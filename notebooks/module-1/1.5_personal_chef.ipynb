{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd6bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from typing import Dict, Any\n",
    "from tavily import TavilyClient\n",
    "\n",
    "tavily_client = TavilyClient()\n",
    "\n",
    "@tool\n",
    "def web_search(query: str) -> Dict[str, Any]:\n",
    "\n",
    "    \"\"\"Search the web for information\"\"\"\n",
    "\n",
    "    return tavily_client.search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "\n",
    "You are a personal chef. The user will give you a list of ingredients they have left over in their house.\n",
    "\n",
    "Using the web search tool, search the web for recipes that can be made with the ingredients they have.\n",
    "\n",
    "Return recipe suggestions and eventually the recipe instructions to the user, if requested.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e227b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "# 1. CONFIGURACIÓN PARA DEEPSEEK-R1 (Razonamiento Complejo)\n",
    "# Ideal para agentes que necesitan planificar pasos lógicos.\n",
    "# llm = ChatBedrock(\n",
    "#     model_id=\"us.deepseek.r1-v1:0\",  # ID oficial validado\n",
    "#     region_name=\"us-east-1\",\n",
    "#     model_kwargs={\n",
    "#         \"temperature\": 0.6, # DeepSeek recomienda 0.6 para razonamiento\n",
    "#         \"max_tokens\": 8192,  # Recomendado para no degradar calidad del CoT\n",
    "#         \"top_p\": 0.95,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "# llm = ChatBedrock(\n",
    "#     model_id=\"us.deepseek.v3-v1:0\", # Prueba este primero\n",
    "#     region_name=\"us-east-1\",        # O us-west-2\n",
    "#     model_kwargs={\n",
    "#         \"temperature\": 0.7,\n",
    "#         \"max_tokens\": 4096\n",
    "#     }\n",
    "# )\n",
    "# from langchain_aws import ChatBedrock\n",
    "# llm = ChatBedrock(\n",
    "# model_id=\"us.meta.llama4-scout-17b-instruct-v1:0\",  # Nota el prefijo \"us.\"\n",
    "# # model_id=\"cohere.command-r-plus-v1:0\",\n",
    "# region_name=\"us-east-1\",\n",
    "# model_kwargs={\n",
    "# \"temperature\": 0.5,\n",
    "# \"max_tokens\": 2048,\n",
    "# \"top_p\": 0.9,\n",
    "# }\n",
    "# )\n",
    "\n",
    "\n",
    "# llm = ChatBedrock(\n",
    "#     model_id=\"us.meta.llama4-maverick-17b-instruct-v1:0\",  # Nota el prefijo \"us.\"\n",
    "#     region_name=\"us-east-1\",\n",
    "#     model_kwargs={\n",
    "#         \"temperature\": 0.5,\n",
    "#         \"max_tokens\": 2048,\n",
    "#         \"top_p\": 0.9,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"amazon.nova-lite-v1:0\",  # Nota el prefijo \"us.\"\n",
    "    region_name=\"us-east-1\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 2048,\n",
    "        \"top_p\": 0.9,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55536d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"I have some leftover chicken and rice. What can I make?\")]},\n",
    "    config\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f768b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d345af09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
