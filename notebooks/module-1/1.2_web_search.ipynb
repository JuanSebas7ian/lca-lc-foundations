{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d7b70b",
   "metadata": {},
   "source": [
    "## Without web search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70738589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a430e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "# 1. CONFIGURACIÓN PARA DEEPSEEK-R1 (Razonamiento Complejo)\n",
    "# Ideal para agentes que necesitan planificar pasos lógicos.\n",
    "# llm = ChatBedrock(\n",
    "#     model_id=\"us.deepseek.r1-v1:0\",  # ID oficial validado\n",
    "#     region_name=\"us-east-1\",\n",
    "#     model_kwargs={\n",
    "#         \"temperature\": 0.6, # DeepSeek recomienda 0.6 para razonamiento\n",
    "#         \"max_tokens\": 8192,  # Recomendado para no degradar calidad del CoT\n",
    "#         \"top_p\": 0.95,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "# llm = ChatBedrock(\n",
    "#     model_id=\"us.deepseek.v3-v1:0\", # Prueba este primero\n",
    "#     region_name=\"us-east-1\",        # O us-west-2\n",
    "#     model_kwargs={\n",
    "#         \"temperature\": 0.7,\n",
    "#         \"max_tokens\": 4096\n",
    "#     }\n",
    "# )\n",
    "# from langchain_aws import ChatBedrock\n",
    "# llm = ChatBedrock(\n",
    "# model_id=\"us.meta.llama4-scout-17b-instruct-v1:0\",  # Nota el prefijo \"us.\"\n",
    "# # model_id=\"cohere.command-r-plus-v1:0\",\n",
    "# region_name=\"us-east-1\",\n",
    "# model_kwargs={\n",
    "# \"temperature\": 0.5,\n",
    "# \"max_tokens\": 2048,\n",
    "# \"top_p\": 0.9,\n",
    "# }\n",
    "# )\n",
    "\n",
    "\n",
    "# llm = ChatBedrock(\n",
    "#     model_id=\"us.meta.llama4-maverick-17b-instruct-v1:0\",  # Nota el prefijo \"us.\"\n",
    "#     region_name=\"us-east-1\",\n",
    "#     model_kwargs={\n",
    "#         \"temperature\": 0.5,\n",
    "#         \"max_tokens\": 2048,\n",
    "#         \"top_p\": 0.9,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"amazon.nova-lite-v1:0\",  # Nota el prefijo \"us.\"\n",
    "    region_name=\"us-east-1\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 2048,\n",
    "        \"top_p\": 0.9,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "question = HumanMessage(content=\"How up to date is your training knowledge?\")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053dbeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03bebb0",
   "metadata": {},
   "source": [
    "## Add web search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9b7652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from typing import Dict, Any\n",
    "from tavily import TavilyClient\n",
    "\n",
    "tavily_client = TavilyClient()\n",
    "\n",
    "@tool\n",
    "def web_search(query: str) -> Dict[str, Any]:\n",
    "\n",
    "    \"\"\"Search the web for information\"\"\"\n",
    "\n",
    "    return tavily_client.search(query)\n",
    "\n",
    "web_search.invoke(\"Who is the current mayor of San Francisco?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537120ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[web_search]\n",
    ")\n",
    "\n",
    "question = HumanMessage(content=\"Who is the current mayor of San Francisco?\")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5ff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd33a79",
   "metadata": {},
   "source": [
    "trace: https://smith.langchain.com/public/59432173-0dd6-49e8-9964-b16be6048426/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54303bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
