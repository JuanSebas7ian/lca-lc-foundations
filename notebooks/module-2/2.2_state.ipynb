{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d180688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de9e5ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentState\n",
    "\n",
    "class CustomState(AgentState):\n",
    "    favourite_colour: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd43d283",
   "metadata": {},
   "source": [
    "## Write to state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b3b8c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.types import Command\n",
    "from langchain.messages import ToolMessage\n",
    "\n",
    "@tool\n",
    "def update_favourite_colour(favourite_colour: str, runtime: ToolRuntime) -> Command:\n",
    "    \"\"\"Update the favourite colour of the user in the state once they've revealed it.\"\"\"\n",
    "    return Command(update={\n",
    "        \"favourite_colour\": favourite_colour, \n",
    "        \"messages\": [ToolMessage(\"Successfully updated favourite colour\", tool_call_id=runtime.tool_call_id)]}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf5d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "# 1. CONFIGURACIÓN PARA DEEPSEEK-R1 (Razonamiento Complejo)\n",
    "# Ideal para agentes que necesitan planificar pasos lógicos.\n",
    "# llm = ChatBedrock(\n",
    "#     model_id=\"us.deepseek.r1-v1:0\",  # ID oficial validado\n",
    "#     region_name=\"us-east-1\",\n",
    "#     model_kwargs={\n",
    "#         \"temperature\": 0.6, # DeepSeek recomienda 0.6 para razonamiento\n",
    "#         \"max_tokens\": 8192,  # Recomendado para no degradar calidad del CoT\n",
    "#         \"top_p\": 0.95,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "# llm = ChatBedrock(\n",
    "#     model_id=\"us.deepseek.v3-v1:0\", # Prueba este primero\n",
    "#     region_name=\"us-east-1\",        # O us-west-2\n",
    "#     model_kwargs={\n",
    "#         \"temperature\": 0.7,\n",
    "#         \"max_tokens\": 4096\n",
    "#     }\n",
    "# )\n",
    "# from langchain_aws import ChatBedrock\n",
    "# llm = ChatBedrock(\n",
    "# model_id=\"us.meta.llama4-scout-17b-instruct-v1:0\",  # Nota el prefijo \"us.\"\n",
    "# # model_id=\"cohere.command-r-plus-v1:0\",\n",
    "# region_name=\"us-east-1\",\n",
    "# model_kwargs={\n",
    "# \"temperature\": 0.5,\n",
    "# \"max_tokens\": 2048,\n",
    "# \"top_p\": 0.9,\n",
    "# }\n",
    "# )\n",
    "\n",
    "\n",
    "# llm = ChatBedrock(\n",
    "#     model_id=\"us.meta.llama4-maverick-17b-instruct-v1:0\",  # Nota el prefijo \"us.\"\n",
    "#     region_name=\"us-east-1\",\n",
    "#     model_kwargs={\n",
    "#         \"temperature\": 0.5,\n",
    "#         \"max_tokens\": 2048,\n",
    "#         \"top_p\": 0.9,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"amazon.nova-lite-v1:0\",  # Nota el prefijo \"us.\"\n",
    "    region_name=\"us-east-1\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 2048,\n",
    "        \"top_p\": 0.9,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830d1c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "response = agent.invoke(\n",
    "    { \"messages\": [HumanMessage(content=\"My favourite colour is green\")]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975f259f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='My favourite colour is green', additional_kwargs={}, response_metadata={}, id='23cd7dab-170d-4ff3-b91b-79da18b71258'),\n",
      "              AIMessage(content=\"\\n\\nGreen is a wonderful colour! It's so calming and natural. What is it about green that you like the most? Is it the way it makes you think of nature and the outdoors, or is there something else that draws you to it?\", additional_kwargs={'usage': {'prompt_tokens': 15, 'completion_tokens': 50, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 65}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 15, 'completion_tokens': 50, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 65}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0', 'model_provider': 'bedrock', 'model_name': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, id='lc_run--019b512e-930d-7fe2-975b-b60d2d6263ed-0', usage_metadata={'input_tokens': 15, 'output_tokens': 50, 'total_tokens': 65, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90bee050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'favourite_colour': 'green',\n",
      " 'messages': [HumanMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={}, id='5f58d5dd-a6dc-4c8b-9416-b4a5843c2458'),\n",
      "              AIMessage(content=\"\\n\\nI'm just a language model, I don't have feelings or emotions like humans do, but I'm functioning properly and ready to help with any questions or tasks you have! How can I assist you today?\", additional_kwargs={'usage': {'prompt_tokens': 16, 'completion_tokens': 41, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 57}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 16, 'completion_tokens': 41, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 57}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0', 'model_provider': 'bedrock', 'model_name': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, id='lc_run--019b512e-b227-7393-a3ab-2609911a2592-0', usage_metadata={'input_tokens': 16, 'output_tokens': 41, 'total_tokens': 57, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}),\n",
      "              HumanMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={}, id='e99698e1-6f0f-474c-8c76-70e7d2c91f8e'),\n",
      "              AIMessage(content=\"\\n\\nI'm doing well, thanks for asking! I'm a large language model, so I don't have feelings or emotions like humans do, but I'm always ready to chat and help with any questions or topics you'd like to discuss. How about you, how's your day going?\", additional_kwargs={'usage': {'prompt_tokens': 72, 'completion_tokens': 55, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 127}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 72, 'completion_tokens': 55, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 127}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0', 'model_provider': 'bedrock', 'model_name': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, id='lc_run--019b512e-d643-7500-87e4-d32a91a244cb-0', usage_metadata={'input_tokens': 72, 'output_tokens': 55, 'total_tokens': 127, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    { \n",
    "        \"messages\": [HumanMessage(content=\"Hello, how are you?\")],\n",
    "        \"favourite_colour\": \"green\"\n",
    "    },\n",
    "    {\"configurable\": {\"thread_id\": \"10\"}}\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6c6710",
   "metadata": {},
   "source": [
    "## Read state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "239059e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "@tool\n",
    "def read_favourite_colour(runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Read the favourite colour of the user from the state.\"\"\"\n",
    "    try:\n",
    "        return runtime.state[\"favourite_colour\"]\n",
    "    except KeyError:\n",
    "        return \"No favourite colour found in state\"\n",
    "\n",
    "agent = create_agent(\n",
    "    #\"amazon.nova-lite-v1:0\",\n",
    "    llm,\n",
    "    tools=[update_favourite_colour, read_favourite_colour],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    state_schema=CustomState\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f4e72b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='My favourite colour is purple', additional_kwargs={}, response_metadata={}, id='1312ece8-9bef-46af-a66e-ff8806387027'),\n",
      "              AIMessage(content=\"\\n\\nPurple is a beautiful and rich colour. It's often associated with creativity, luxury, and wisdom. What is it about purple that you like the most? Is it a particular shade, like lavender or plum, or is it the way it makes you feel?\", additional_kwargs={'usage': {'prompt_tokens': 15, 'completion_tokens': 53, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 68}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 15, 'completion_tokens': 53, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 68}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0', 'model_provider': 'bedrock', 'model_name': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, id='lc_run--019b512f-421a-7c60-baac-4a0c7729879c-0', usage_metadata={'input_tokens': 15, 'output_tokens': 53, 'total_tokens': 68, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    { \"messages\": [HumanMessage(content=\"My favourite colour is purple\")]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1483dac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='My favourite colour is purple', additional_kwargs={}, response_metadata={}, id='1312ece8-9bef-46af-a66e-ff8806387027'),\n",
      "              AIMessage(content=\"\\n\\nPurple is a beautiful and rich colour. It's often associated with creativity, luxury, and wisdom. What is it about purple that you like the most? Is it a particular shade, like lavender or plum, or is it the way it makes you feel?\", additional_kwargs={'usage': {'prompt_tokens': 15, 'completion_tokens': 53, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 68}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 15, 'completion_tokens': 53, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 68}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0', 'model_provider': 'bedrock', 'model_name': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, id='lc_run--019b512f-421a-7c60-baac-4a0c7729879c-0', usage_metadata={'input_tokens': 15, 'output_tokens': 53, 'total_tokens': 68, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}),\n",
      "              HumanMessage(content=\"What's my favourite colour?\", additional_kwargs={}, response_metadata={}, id='7a0f77a3-8a5d-4017-b8fb-fa9f37513893'),\n",
      "              AIMessage(content='\\n\\nYour favourite colour is purple! You told me that earlier.', additional_kwargs={'usage': {'prompt_tokens': 82, 'completion_tokens': 14, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 96}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 82, 'completion_tokens': 14, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 96}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0', 'model_provider': 'bedrock', 'model_name': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, id='lc_run--019b512f-7e85-7792-8054-af469bd8754a-0', usage_metadata={'input_tokens': 82, 'output_tokens': 14, 'total_tokens': 96, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    { \"messages\": [HumanMessage(content=\"What's my favourite colour?\")]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec54c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock  # ChatBedrock normal\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# Estos modelos SÍ funcionan con ChatBedrock:\n",
    "working_models = [\n",
    "    \"anthropic.claude-sonnet-4-20250514-v3:0\",  # Claude\n",
    "    \"amazon.nova-pro-v1:0\",                       # Nova\n",
    "    \"mistral.mistral-large-2407-v1:0\",           # Mistral\n",
    "]\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"mistral.mistral-large-2407-v1:0\",  # Usa uno de estos\n",
    "    region_name=\"us-east-1\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_tokens\": 1024,\n",
    "    }\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    llm,\n",
    "    tools=[update_favourite_colour, read_favourite_colour],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    state_schema=CustomState\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe23f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"cohere.command-r-plus-v1:0\"\n",
    "model_id = \"us.meta.llama4-scout-17b-instruct-v1:0\"\n",
    "\n",
    "# Usar ChatBedrockConverse en lugar de ChatBedrock\n",
    "llm = ChatBedrockConverse(\n",
    "    model=model_id,\n",
    "    region_name=\"us-east-1\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1024,\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    llm,\n",
    "    tools=[update_favourite_colour, read_favourite_colour],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    state_schema=CustomState\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"My favourite colour is green\")]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")\n",
    "\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccaa951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
