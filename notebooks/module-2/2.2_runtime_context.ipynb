{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00525f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13dbd3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ColourContext:\n",
    "    favourite_colour: str = \"blue\"\n",
    "    least_favourite_colour: str = \"yellow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03be72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"us.meta.llama4-maverick-17b-instruct-v1:0\",  # Nota el prefijo \"us.\"\n",
    "    region_name=\"us-east-1\",\n",
    "    beta_use_converse_api=True,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 2048,\n",
    "        \"top_p\": 0.9,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"nova\",\n",
    "    context_schema=ColourContext  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eec82bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is my favourite colour?\")]},\n",
    "    context=ColourContext()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9e923d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is my favourite colour?', additional_kwargs={}, response_metadata={}, id='e3f37906-c3a9-4cda-9c00-4397b9b67470'),\n",
      "              AIMessage(content=\"\\n\\nYou haven't told me your favourite colour, so I don't have any information about it. If you'd like to share, I'd be happy to remember it for our conversation!\", additional_kwargs={'usage': {'prompt_tokens': 16, 'completion_tokens': 35, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 51}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 16, 'completion_tokens': 35, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 51}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0', 'model_provider': 'bedrock', 'model_name': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, id='lc_run--019b4e35-295a-7bf3-b1f6-12b51c377ebb-0', usage_metadata={'input_tokens': 16, 'output_tokens': 35, 'total_tokens': 51, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24874360",
   "metadata": {},
   "source": [
    "## Accessing Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dca527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "@tool\n",
    "def get_favourite_colour(runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Get the favourite colour of the user\"\"\"\n",
    "    return runtime.context.favourite_colour\n",
    "\n",
    "@tool\n",
    "def get_least_favourite_colour(runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Get the least favourite colour of the user\"\"\"\n",
    "    return runtime.context.least_favourite_colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce743296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_favourite_colour, get_least_favourite_colour],\n",
    "    context_schema=ColourContext\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f07e137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is my favourite colour?. Could you read the @tool.', additional_kwargs={}, response_metadata={}, id='309635bc-e3e5-493e-8f00-6cafaf5ba4eb'),\n",
      "              AIMessage(content='\\n\\nI don\\'t have have access to any external tools or data about you, so I\\'m unable to read any \"@tool\" or know your personal preferences, including your favourite colour. However, I can try to help you discover or decide on a favourite colour if you\\'d like to discuss it!', additional_kwargs={'usage': {'prompt_tokens': 23, 'completion_tokens': 58, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 81}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 23, 'completion_tokens': 58, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 81}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0', 'model_provider': 'bedrock', 'model_name': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, id='lc_run--019b4e3d-43c3-74c0-aa57-fd6822287402-0', usage_metadata={'input_tokens': 23, 'output_tokens': 58, 'total_tokens': 81, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is my favourite colour?. Could you read the @tool.\")]},\n",
    "    context=ColourContext()\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f68fc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is my favourite colour? ', additional_kwargs={}, response_metadata={}, id='689b8424-aec5-4cdb-bd88-0b719b54abde'),\n",
      "              AIMessage(content=\"\\n\\nYou haven't told me your favourite colour, so I don't have any information about it. If you'd like to share, I'd be happy to remember it for our conversation!\", additional_kwargs={'usage': {'prompt_tokens': 17, 'completion_tokens': 35, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 52}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 17, 'completion_tokens': 35, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 52}, 'stop_reason': 'stop', 'thinking': {}, 'model_id': 'us.meta.llama4-maverick-17b-instruct-v1:0', 'model_provider': 'bedrock', 'model_name': 'us.meta.llama4-maverick-17b-instruct-v1:0'}, id='lc_run--019b4e3f-8e9d-7772-bd94-c5f342877b7e-0', usage_metadata={'input_tokens': 17, 'output_tokens': 35, 'total_tokens': 52, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is my favourite colour? \")]},\n",
    "    context=ColourContext(favourite_colour=\"green\")\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4adca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
