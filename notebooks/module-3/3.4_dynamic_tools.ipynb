{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "939ecc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d95aa0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from typing import Dict, Any\n",
    "from tavily import TavilyClient\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "tavily_client = TavilyClient()\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///resources/Chinook.db\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def web_search(query: str) -> Dict[str, Any]:\n",
    "\n",
    "    \"\"\"Search the web for information\"\"\"\n",
    "\n",
    "    return tavily_client.search(query)\n",
    "\n",
    "@tool\n",
    "def sql_query(query: str) -> str:\n",
    "\n",
    "    \"\"\"Obtain information from the database using SQL queries\"\"\"\n",
    "\n",
    "    try:\n",
    "        return db.run(query)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633e84a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class UserRole:\n",
    "    user_role: str = \"external\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c8729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from typing import Callable\n",
    "\n",
    "@wrap_model_call\n",
    "def dynamic_tool_call(request: ModelRequest, \n",
    "handler: Callable[[ModelRequest], ModelResponse]) -> ModelResponse:\n",
    "\n",
    "    \"\"\"Dynamically call tools based on the runtime context\"\"\"\n",
    "\n",
    "    user_role = request.runtime.context.user_role\n",
    "    \n",
    "    if user_role == \"internal\":\n",
    "        pass # internal users get access to all tools\n",
    "    else:\n",
    "        tools = [web_search] # external users only get access to web search\n",
    "        request = request.override(tools=tools) \n",
    "\n",
    "    return handler(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "105b9117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "# 1. CONFIGURACIÓN PARA DEEPSEEK-R1 (Razonamiento Complejo)\n",
    "# Ideal para agentes que necesitan planificar pasos lógicos.\n",
    "# llm = ChatBedrock(\n",
    "#     model_id=\"us.deepseek.r1-v1:0\",  # ID oficial validado\n",
    "#     region_name=\"us-east-1\",\n",
    "#     model_kwargs={\n",
    "#         \"temperature\": 0.6, # DeepSeek recomienda 0.6 para razonamiento\n",
    "#         \"max_tokens\": 8192,  # Recomendado para no degradar calidad del CoT\n",
    "#         \"top_p\": 0.95,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "# llm = ChatBedrock(\n",
    "#     model_id=\"us.deepseek.v3-v1:0\", # Prueba este primero\n",
    "#     region_name=\"us-east-1\",        # O us-west-2\n",
    "#     model_kwargs={\n",
    "#         \"temperature\": 0.7,\n",
    "#         \"max_tokens\": 4096\n",
    "#     }\n",
    "# )\n",
    "# from langchain_aws import ChatBedrock\n",
    "# llm = ChatBedrock(\n",
    "# model_id=\"us.meta.llama4-scout-17b-instruct-v1:0\",  # Nota el prefijo \"us.\"\n",
    "# # model_id=\"cohere.command-r-plus-v1:0\",\n",
    "# region_name=\"us-east-1\",\n",
    "# model_kwargs={\n",
    "# \"temperature\": 0.5,\n",
    "# \"max_tokens\": 2048,\n",
    "# \"top_p\": 0.9,\n",
    "# }\n",
    "# )\n",
    "\n",
    "\n",
    "# llm = ChatBedrock(\n",
    "#     model_id=\"us.meta.llama4-maverick-17b-instruct-v1:0\",  # Nota el prefijo \"us.\"\n",
    "#     region_name=\"us-east-1\",\n",
    "#     model_kwargs={\n",
    "#         \"temperature\": 0.5,\n",
    "#         \"max_tokens\": 2048,\n",
    "#         \"top_p\": 0.9,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"amazon.nova-lite-v1:0\",  # Nota el prefijo \"us.\"\n",
    "    region_name=\"us-east-1\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 2048,\n",
    "        \"top_p\": 0.9,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ebdbe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[web_search, sql_query],\n",
    "    middleware=[dynamic_tool_call],\n",
    "    context_schema=UserRole\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9833e543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking>I have found several sources that mention the number of artists in a database, but they are all different. The first source mentions a database of 16,000 artists used to train Midjourney AI, but it doesn't specify if this is the total number of artists in the database. The second source mentions a database of 370,062 artists, but it's unclear if this is the total number of artists in the database or just the number of artists in a specific category. The third source mentions a database of over 1.4 million musical artists, but it's unclear if this is the total number of artists in the database or just the number of artists in a specific category. The fourth source mentions a music library with 1,312 artists, but it's unclear if this is the total number of artists in the database or just the number of artists in a specific category. The fifth source mentions a database with 2.7 million artists, but it's unclear if this is the total number of artists in the database or just the number of artists in a specific category. I need to find a source that clearly states the total number of artists in the database.</thinking>\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"How many artists are in the database?\")]},\n",
    "    context={\"user_role\": \"external\"}\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80422889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<thinking>I have found several sources that mention the number of artists in a database, but they are all different. The first source mentions a database of 16,000 artists used to train Midjourney AI, but it doesn't specify if this is the total number of artists in the database. The second source mentions a database of 370,062 artists, but it's unclear if this is the total number of artists in the database or just the number of artists in a specific category. The third source mentions a database of over 1.4 million musical artists, but it's unclear if this is the total number of artists in the database or just the number of artists in a specific category. The fourth source mentions a music library with 1,312 artists, but it's unclear if this is the total number of artists in the database or just the number of artists in a specific category. The fifth source mentions a database with 2.7 million artists, but it's unclear if this is the total number of artists in the database or just the number of artists in a specific category. I need to find a source that clearly states the total number of artists in the database.</thinking>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "display(Markdown(response[\"messages\"][-1].content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796dd4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
